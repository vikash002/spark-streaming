sudo  /bin/spark-submit --total-executor-cores 4 --supervise --driver-java-options "-Dcom.sun.management.jmxremote.port=45620 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.net.preferIPv4Stack=true -XX:+UseG1GC -XX:+PrintFlagsFinal -XX:+PrintReferenceGC -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintAdaptiveSizePolicy -XX:+UnlockDiagnosticVMOptions -XX:+G1SummarizeConcMark -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=128K -XX:+HeapDumpOnOutOfMemoryError  -Xloggc:/var/lib/fk-pf-spark/logs/driver-sfc-tasks-gc.log " --conf "-Djava.net.preferIPv4Stack=true -XX:+UseG1GC -XX:+PrintFlagsFinal -XX:+PrintReferenceGC -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintAdaptiveSizePolicy -XX:+UnlockDiagnosticVMOptions -XX:+G1SummarizeConcMark -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=128K -XX:+HeapDumpOnOutOfMemoryError" --conf "spark.executor.extraClassPath=../spark-streaming-1.0-SNAPSHOT.jar" --driver-class-path "../spark-streaming-1.0-SNAPSHOT.jar" --driver-memory 4g --class "org.spark.streaming.common.sparkjob.SparkJobMain" ../spark-streaming-1.0-SNAPSHOT.jar SparkProd.yml USER_UPDATE &